{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592b703",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c298b9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "scraped_csv_path = '../data/raw/telegram_data.csv'\n",
    "\n",
    "try:\n",
    "    df_scraped = pd.read_csv(../data/raw/telegram_data.csv, encoding='utf-8')\n",
    "    print(f\"Loaded scraped data from: {../data/raw/telegram_data.csv}\")\n",
    "    print(f\"Shape of scraped data: {df_scraped.shape}\")\n",
    "    print(\"\\nFirst 5 rows of scraped data:\")\n",
    "    print(df_scraped.head())\n",
    "    print(\"\\nColumn information:\")\n",
    "    print(df_scraped.info())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{scraped_csv_path}' was not found.\")\n",
    "    print(\"Please ensure the 'telegram_scraper.py' script was run successfully and created the CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the scraped CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a31fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def clean_amharic_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Return empty string for non-string types (e.g., NaN)\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\s+O\\s*', ' ', text) \n",
    "    text = re.sub(r'O\\s+', '', text)    \n",
    "    text = re.sub(r'\\s+O$', '', text)   \n",
    "\n",
    "    text = re.sub(r'[\\u1361-\\u1368]', ' ', text) # Remove Ethiopian punctuation marks if desired\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "if 'Message' in df_scraped.columns:\n",
    "    df_scraped['Cleaned_Message'] = df_scraped['Message'].fillna('').apply(clean_amharic_text)\n",
    "    print(\"\\nCleaned 'Message' column and created 'Cleaned_Message'.\")\n",
    "    print(\"\\nSample of cleaned messages:\")\n",
    "    for i, row in df_scraped.sample(min(5, len(df_scraped))).iterrows():\n",
    "        print(f\"Original: {row['Message']}\")\n",
    "        print(f\"Cleaned:  {row['Cleaned_Message']}\\n\")\n",
    "else:\n",
    "    print(\"Error: 'Message' column not found in scraped data DataFrame. Cannot perform cleaning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09c288",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "labeled_data_path = '../labeled_telegram_product_price_location.txt'\n",
    "\n",
    "def parse_conll_file(filepath):\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line: \n",
    "                parts = line.split(' ')\n",
    "                token = ' '.join(parts[:-1]) \n",
    "                label = parts[-1]\n",
    "                current_sentence.append((token, label))\n",
    "            else: \n",
    "                if current_sentence:\n",
    "                    sentences.append(current_sentence)\n",
    "                current_sentence = []\n",
    "        if current_sentence:\n",
    "            sentences.append(current_sentence)\n",
    "    return sentences\n",
    "\n",
    "try:\n",
    "    labeled_sentences = parse_conll_file(labeled_data_path)\n",
    "    print(f\"\\nLoaded labeled data from: {labeled_data_path}\")\n",
    "    print(f\"Number of labeled sentences: {len(labeled_sentences)}\")\n",
    "    print(\"\\nFirst labeled sentence example (token, label):\")\n",
    "    if labeled_sentences:\n",
    "        for token, label in labeled_sentences[0]:\n",
    "            print(f\"  {token}\\t{label}\")\n",
    "    else:\n",
    "        print(\"No sentences found in labeled data.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The labeled data file '{labeled_data_path}' was not found.\")\n",
    "    print(\"Please ensure 'labeled_telegram_product_price_location.txt' is in your project root.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while parsing the labeled CoNLL file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f1a66",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "processed_scraped_csv_path = '../data/processed/cleaned_telegram_data.csv'\n",
    "os.makedirs(os.path.dirname(processed_scraped_csv_path), exist_ok=True)\n",
    "if 'df_scraped' in locals() and 'Cleaned_Message' in df_scraped.columns:\n",
    "    df_scraped.to_csv(processed_scraped_csv_path, index=False, encoding='utf-8')\n",
    "    print(f\"\\nCleaned scraped data saved to: {processed_scraped_csv_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nLabeled data is parsed and ready in 'labeled_sentences' variable.\")\n",
    "print(\"This parsed labeled data ('labeled_sentences') will be directly used in Task 3 for fine-tuning the NER model.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
